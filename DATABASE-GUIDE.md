# Database Guide - Docker vs Local PostgreSQL

## ðŸ—„ï¸ Understanding Your Database Setup

### What's Happening Now

You have **TWO separate PostgreSQL databases**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Local PostgreSQL (Windows)   â”‚
â”‚                                     â”‚
â”‚  Location: localhost:5432           â”‚
â”‚  Status: Still running (maybe)      â”‚
â”‚  Data: ALL YOUR OLD DATA IS HERE   â”‚
â”‚  âŒ Docker is NOT using this        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Docker PostgreSQL (Container)     â”‚
â”‚                                     â”‚
â”‚  Location: Inside Docker container  â”‚
â”‚  Exposed at: localhost:5432         â”‚
â”‚  Data: Empty (just schema)          â”‚
â”‚  âœ… Docker backend uses this        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Important**: When Docker is running, it "takes over" port 5432, so your local PostgreSQL might be blocked or running on a different port.

---

## ðŸŽ¯ Your Options

### Option 1: Use Docker PostgreSQL (Current Setup) â­ Recommended

**Pros:**
- âœ… Everything in Docker is portable
- âœ… Easy to deploy to servers
- âœ… Isolated environment
- âœ… No conflicts with other apps

**Cons:**
- âŒ Your old data is not automatically migrated
- âŒ Need to export/import data manually

**What you have now:**
- Empty database with schema
- One Super Admin account:
  - Phone: `9999999999`
  - Password: `admin`

---

### Option 2: Point Docker Backend to Your Local PostgreSQL

**Make Docker use your Windows PostgreSQL instead of the container.**

#### Steps:

1. **Edit `docker-compose.yml`:**

```yaml
services:
  # Comment out the postgres service
  # postgres:
  #   image: postgres:16-alpine
  #   ...

  backend:
    environment:
      # Change this line:
      DATABASE_URL: postgresql://postgres:password@host.docker.internal:5432/farmer_buyer_db
      # (host.docker.internal = your Windows machine from inside Docker)
```

2. **Restart:**
```bash
docker-compose down
docker-compose up -d
```

3. **Make sure your local PostgreSQL is running.**

**Pros:**
- âœ… Access all your existing data immediately
- âœ… No data migration needed

**Cons:**
- âŒ Not portable (requires PostgreSQL installed)
- âŒ Harder to deploy to other servers

---

### Option 3: Migrate Your Data from Local to Docker

**Copy your existing data into the Docker PostgreSQL.**

#### Method A: Using pg_dump (if you have PostgreSQL tools installed)

```bash
# 1. Export from local PostgreSQL
pg_dump -U postgres -h localhost -p 5432 farmer_buyer_db > backup.sql

# 2. Import into Docker
cat backup.sql | docker-compose exec -T postgres psql -U postgres farmer_buyer_db
```

#### Method B: Using Prisma Studio (Visual Tool)

```bash
# 1. Start Prisma Studio for Docker database
docker-compose exec backend npx prisma studio

# 2. Manually add your data through the web UI
# Opens at http://localhost:5555
```

#### Method C: Export/Import via CSV

If you have the data in CSV files or can export it:

```bash
# Copy CSV files into container
docker cp your_data.csv farmer-buyer-db:/tmp/

# Import via psql
docker-compose exec postgres psql -U postgres farmer_buyer_db -c "\copy users FROM '/tmp/your_data.csv' DELIMITER ',' CSV HEADER"
```

---

## ðŸ”§ Quick Actions

### Check What's in Docker Database Now

```bash
# Open Prisma Studio
docker-compose exec backend npx prisma studio
```

Opens a web UI at http://localhost:5555 to view/edit your database.

### Run the Seed Again (if needed)

```bash
docker-compose exec backend npm run seed
```

Creates the Super Admin account (Phone: 9999999999, Password: admin).

### Connect to Docker PostgreSQL Directly

```bash
# Open PostgreSQL shell
docker-compose exec postgres psql -U postgres farmer_buyer_db

# Then you can run SQL commands
SELECT * FROM users;
```

---

## ðŸ“Š Current Database Status

### Docker PostgreSQL Contents:

| Table | Records |
|-------|---------|
| users | 1 (Super Admin) |
| All other tables | Empty |

**Login credentials:**
- Phone: `9999999999`
- Password: `admin`
- Role: ADMIN

---

## ðŸ’¡ Recommendations

### For Development (Right Now)
**Use Option 1 (Docker PostgreSQL)** and seed with test data as needed.

### For Production Deployment
**Use Option 1** - Keep everything in Docker for portability.

### If You MUST Have Your Old Data
**Use Option 3** - Migrate data from local to Docker.

---

## ðŸ†˜ Troubleshooting

### "Can't connect to my local PostgreSQL anymore"

When Docker runs, it uses port 5432. To check if your local PostgreSQL is running:

```powershell
# Check if local PostgreSQL is running
Get-Service postgresql*

# Check what's using port 5432
netstat -ano | findstr :5432
```

You might need to:
1. Stop Docker: `docker-compose down`
2. Start local PostgreSQL
3. Or change Docker postgres port in `docker-compose.yml`:
   ```yaml
   postgres:
     ports:
       - "5433:5432"  # Use 5433 externally, 5432 inside container
   ```

### "I want to start fresh"

```bash
# Delete everything (including data)
docker-compose down -v

# Start fresh
docker-compose up -d

# Seed the database
docker-compose exec backend npm run seed
```

---

## ðŸ“š Next Steps

1. **Decide which option** you want to use (Docker DB vs Local DB)
2. **If using Docker DB**: Decide if you need to migrate old data
3. **If yes, migrate**: Use one of the methods in Option 3
4. **If no**: Just use the seeded Super Admin account and create new data

**Your current setup is ready to use!** You can log in with the Super Admin credentials and start testing. ðŸš€
